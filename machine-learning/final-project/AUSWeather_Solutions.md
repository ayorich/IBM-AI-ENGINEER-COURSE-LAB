# Australian Weather Rainfall Prediction - Complete Solutions

## Exercise 1: Map the dates to seasons and drop the Date column

```python
# Convert the 'Date' column to datetime format
df['Date'] = pd.to_datetime(df['Date'])

# Apply the function to the 'Date' column
df['Season'] = df['Date'].apply(date_to_season)

df = df.drop(columns=['Date'])
df
```

## Exercise 2: Define the feature and target dataframes

```python
X = df.drop(columns='RainToday', axis=1)
y = df['RainToday']
```

## Exercise 3: How balanced are the classes?

```python
y.value_counts()
```

**Expected Output:**
```
No     5766
Yes    1791
Name: RainToday, dtype: int64
```

## Exercise 4: What can you conclude from these counts?

**Analysis:**

- **Annual rainfall frequency**: It rains approximately 23.7% of the time in the Melbourne area (1791 rainy days out of 7557 total days)
- **Baseline accuracy**: If we assumed it won't rain every day, we would be correct 76.3% of the time (5766 out of 7557 days)
- **Dataset balance**: This is an imbalanced dataset - there are significantly more "No" (no rain) instances than "Yes" (rain) instances
- **Next steps**: We should use stratified sampling for train/test split and consider class weights in our models to handle the imbalance

## Exercise 5: Split data into training and test sets, ensuring target stratification

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
```

## Exercise 6: Automatically detect numerical and categorical columns

```python
numeric_features = X_train.select_dtypes(include=['number']).columns.tolist()
categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()
```

## Exercise 7: Combine the transformers into a single preprocessing column transformer

```python
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)
```

## Exercise 8: Create a pipeline by combining the preprocessing with a Random Forest classifier

```python
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])
```

## Exercise 9: Instantiate and fit GridSearchCV to the pipeline

```python
grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='accuracy', verbose=2)
grid_search.fit(X_train, y_train)
```

## Exercise 10: Display your model's estimated score

```python
test_score = grid_search.score(X_test, y_test)
print("Test set score: {:.2f}".format(test_score))
```

**Expected Output:**
```
Test set score: 0.83
```

## Exercise 11: Get the model predictions from the grid search estimator on the unseen data

```python
y_pred = grid_search.predict(X_test)
```

## Exercise 12: Print the classification report

```python
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
```

**Expected Output:**
```
              precision    recall  f1-score   support

          No       0.85      0.95      0.90      1154
         Yes       0.73      0.47      0.58       358

    accuracy                           0.83      1512
   macro avg       0.79      0.71      0.74      1512
weighted avg       0.82      0.83      0.82      1512
```

## Exercise 13: Plot the confusion matrix

```python
conf_matrix = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)
disp.plot(cmap='Blues')
plt.title('Confusion Matrix')
plt.show()
```

## Exercise 14: Extract the feature importances

```python
feature_importances = grid_search.best_estimator_['classifier'].feature_importances_
```

## Exercise 15: Update the pipeline and the parameter grid

```python
# Replace RandomForestClassifier with LogisticRegression
pipeline.set_params(classifier=LogisticRegression(random_state=42))

# update the model's estimator to use the new pipeline
grid_search.estimator = pipeline

# Define a new grid with Logistic Regression parameters
param_grid = {
    'classifier__solver' : ['liblinear'],
    'classifier__penalty': ['l1', 'l2'],
    'classifier__class_weight' : [None, 'balanced']
}

grid_search.param_grid = param_grid

# Fit the updated pipeline with LogisticRegression
grid_search.fit(X_train, y_train)

# Make predictions
y_pred = grid_search.predict(X_test)
```

## Points to Note - Complete Analysis

### Point 1: Features inefficient for predicting tomorrow's rainfall
- **Rainfall**: This is today's rainfall, which directly indicates if it rained today
- **RainToday**: This is the target variable we're trying to predict
- **Evaporation**: Measured over the entire day, so not available until the end of the day
- **Sunshine**: Total hours of sunshine for the entire day
- **Cloud3pm**: Cloud cover at 3pm (available during the day)

These features would cause data leakage because they use information from the entire day or later in the day to predict rainfall that occurred earlier.

### Point 2: True Positive Rate Analysis
From the Random Forest confusion matrix:
- **True Positives**: ~168 (correctly predicted rain)
- **False Negatives**: ~190 (missed rain predictions)
- **True Positive Rate (Recall)**: 168/(168+190) â‰ˆ 0.47 or 47%

This means the model correctly identifies 47% of actual rainy days.

### Point 3: Most Important Feature
Based on the feature importance plot, the most important feature for predicting rainfall is typically **Humidity9am** (humidity at 9am), followed by **Pressure9am** and **Temp9am**.

### Point 4: Model Comparison
**Random Forest vs Logistic Regression Performance:**

1. **Accuracy Comparison**:
   - Random Forest: ~83% accuracy
   - Logistic Regression: ~83% accuracy
   - Both models perform similarly overall

2. **True Positive Rate (Recall for "Yes" class)**:
   - Random Forest: ~47% recall
   - Logistic Regression: ~51% recall
   - Logistic Regression is slightly better at identifying rainy days

3. **Precision for "Yes" class**:
   - Random Forest: ~73% precision
   - Logistic Regression: ~68% precision
   - Random Forest has fewer false positives

4. **Overall Assessment**:
   - Both models perform similarly for this imbalanced dataset
   - Both models struggle with the minority class (rainy days)
   - The class imbalance makes this a challenging prediction task

## Key Insights

1. **Class Imbalance**: The dataset is imbalanced with ~76.3% "No rain" and ~23.7% "Rain" days
2. **Baseline Performance**: A naive "always predict no rain" approach would achieve 76.3% accuracy
3. **Model Performance**: Both models improve significantly over the baseline, with similar performance between Random Forest and Logistic Regression
4. **Feature Importance**: Morning humidity and pressure are the most predictive features
5. **Practical Application**: The models could be useful for weather forecasting, though they still miss about 53% of rainy days

## Recommendations for Improvement

1. **Feature Engineering**: Create interaction features between humidity, pressure, and temperature
2. **Data Augmentation**: Collect more data or use techniques to balance the classes
3. **Ensemble Methods**: Combine multiple models for better performance
4. **Hyperparameter Tuning**: Expand the parameter grid for more thorough optimization
5. **Cross-Validation**: Use time-series cross-validation to account for temporal dependencies 